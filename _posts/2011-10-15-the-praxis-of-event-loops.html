---
layout: post
title: The Praxis of Event Loops
date: 2011-10-15 15:27:47.000000000 +01:00
categories:
- Future
tags: []
status: publish
type: post
published: true
meta:
  _edit_last: '1'
  tmac_last_id: '531409133703299074'
  _jetpack_related_posts_cache: a:1:{s:32:"8f6677c9d6b0f903e98ad32ec61f8deb";a:2:{s:7:"expires";i:1415511168;s:7:"payload";a:3:{i:0;a:1:{s:2:"id";i:8;}i:1;a:1:{s:2:"id";i:315;}i:2;a:1:{s:2:"id";i:340;}}}}
  _wpcom_is_markdown: '1'
author:
  login: admin
  email: brunofr@olympum.com
  display_name: Bruno Fernandez-Ruiz
  first_name: Bruno
  last_name: Fernandez-Ruiz
---
<p>On a theoretical world, given the ability for a processor to run an infinite<br />
amount of threads, we could prove the following statements (no attribution<br />
purposely given):</p>
<ul>
<li>If you do more CPU than I/O, use threads.</li>
<li>If you do more I/O than CPU, use more threads.</li>
</ul>
<p>which would allow us to conclude with the following corollary:</p>
<blockquote><p>
  at full utilization, threads and events have the same theoretical<br />
  throughput.
</p></blockquote>
<p>Such argument ignores <strong>praxis</strong> -- it is a purely <strong>theoretical</strong> debate<br />
disconnected from the reality of scaling services --.</p>
<p>Yahoo! serves over 20 billion daily requests through it's edge services<br />
(remote proxies and caches throughout the world). These intermediate servers<br />
are doing pure IO workloads, handling slow client IO and handing connections<br />
off to the origin servers through Yahoo's pipes. It is critical that we<br />
minimize the CPU cost per connection to be able to max the CPU at the max<br />
number of connections per host.</p>
<p>The hosts on Yahoo!s edge network run exclusively event loops, and have been<br />
doing so for over a decade, originally with Inktomi Traffic Server then with<br />
Yahoo Traffic Server, and now with Apache Traffic Server, etc. The design<br />
throughout is the same: a few "master" event loop threads, usually one per<br />
core, and a small pool of worker threads. In total, a handful of 20~50 threads<br />
per server. With this design, Yahoo! is able to scale to hundreds of thousands<br />
of connections per server. It is currently still impossible, <em>in practice</em>, to<br />
run a server with so many threads and still serve data.</p>
<p>Another practical need for event loops occurs at the other end of the serving<br />
stack. Resolving a search query follows a general pattern of parsing and<br />
rewriting the query, followed by fetching potential search results, and<br />
finally doing document re-ranking. The first and last phases are CPU<br />
intensive. The fetch operation is purely an IO workload that performs a<br />
scatter-gather operation which fans out to hundreds to thousands of back<br />
servers holding the search index across tens of columns. As a consequence, for<br />
every client connection, it's possible to require one thousand upstream<br />
connections. When the upstream index servers become slow, which is a common<br />
failure situation, or perhaps in scenarios where we have to fetch data from a<br />
remote data center, the number of connections in the system grows to tens of<br />
thousands. It is also important that we keep all three phases running on the<br />
same process to avoid serialization and transfer costs, essentially forcing us<br />
to mix CPU and IO intensive workload. It is currently still impossible, <em>in<br />
practice</em>, to perform this type of data intensive processing without using<br />
event loops.</p>
<p>Unlike Yahoo's services, which combine an event loop with a handful of threads<br />
per core, Node.JS design is a single-threaded event-loop per core. For pure IO<br />
workloads this ensures the necessary simplicity required to be able to design<br />
software that scales to thousands of concurrent active connections, as long as<br />
nothing is blocking. I find it unfortunate that some developers have not<br />
internalized this and are trying to run CPU intensive applications using<br />
Node.JS. Inferring that because these badly designed applications are a<br />
failure, therefore Node.JS is a failure is an unnecessary and unfair<br />
generalization. Node.JS has a field of <em>practical</em> applicability, and like any<br />
tool, a seasoned practitioner should know when, and when not, to use it.</p>
